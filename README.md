# ğŸ¨ PDI Studio AI

Estudio de Procesamiento Digital de ImÃ¡genes (PDI) en Tiempo Real con IA

Este es un estudio de procesamiento digital de imÃ¡genes en tiempo real, potenciado por un Modelo de Lenguaje Grande (LLM) local. La aplicaciÃ³n permite a los usuarios aplicar una variedad de filtros de imagen a un feed de cÃ¡mara en vivo o a imÃ¡genes cargadas, con la capacidad Ãºnica de generar pipelines de procesamiento complejas utilizando lenguaje natural.

## âœ¨ CaracterÃ­sticas Principales

    Procesamiento de ImÃ¡genes en Tiempo Real: Aplica filtros a un feed de cÃ¡mara en vivo, observando los resultados instantÃ¡neamente.

    GeneraciÃ³n de Pipelines con IA (LLM Local): Describe el efecto de imagen deseado en lenguaje natural, y un LLM local generarÃ¡ una secuencia de filtros (pipeline) para lograrlo.

    GestiÃ³n de Pipelines Flexible:

        - AÃ±ade y elimina filtros de la pipeline.

        - Modifica los parÃ¡metros de los filtros individualmente mediante controles deslizantes e inputs numÃ©ricos.

        - Activa o desactiva filtros especÃ­ficos en la pipeline.

    PrevisualizaciÃ³n y AnÃ¡lisis:

        - Visualiza el histograma de la imagen procesada para comprender mejor la distribuciÃ³n de pÃ­xeles.

        - Guarda capturas de pantalla de la imagen procesada.

    GestiÃ³n de Presets:

        - Guarda tus pipelines de filtros favoritas como presets para su uso futuro.

        - Carga y elimina presets existentes.

    Interfaz de Usuario Intuitiva: Desarrollada con PyQt6 para una experiencia de usuario fluida y reactiva.

## ğŸš€ CÃ³mo Empezar

Sigue estos pasos para configurar y ejecutar PDI Studio AI en tu mÃ¡quina local.

Requisitos

    - Python 3.8 o superior

    - Pip (gestor de paquetes de Python)

    - Una webcam (opcional, si deseas usar el feed en vivo)

    - Suficiente RAM y/o VRAM para el modelo LLM (al menos 4GB de RAM son recomendables para el Phi-3-mini-4k-instruct-q4.gguf en CPU, mÃ¡s para GPU).

## âš™ï¸ InstalaciÃ³n

    Clona el repositorio:

```Bash

git clone https://github.com/tu-usuario/pdi_studio_ai.git
cd pdi_studio_ai
``` 

(AsegÃºrate de reemplazar tu-usuario con tu nombre de usuario de GitHub si lo subes a tu cuenta personal).

Crea y activa un entorno virtual (recomendado):

```Bash
python -m venv venv
# En Windows:
.\venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate
```

Instala las dependencias de Python:

```Bash
pip install -r requirements.txt
```

Si tienes una GPU NVIDIA y quieres usarla para el LLM, instala llama-cpp-python con soporte CUDA:

```Bash
pip uninstall llama-cpp-python # Desinstala la versiÃ³n solo CPU si ya estÃ¡ instalada
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
```

(AsegÃºrate de que cu121 coincida con tu versiÃ³n de CUDA. Consulta la documentaciÃ³n de llama-cpp-python para mÃ¡s detalles si tu versiÃ³n de CUDA es diferente).

Descarga el modelo LLM:
PDI Studio AI utiliza el modelo Phi-3-mini-4k-instruct-q4.gguf. Debes descargarlo manualmente y colocarlo en la carpeta models/ dentro del directorio raÃ­z del proyecto.

    Descarga el modelo desde Hugging Face:
    microsoft/Phi-3-mini-4k-instruct-gguf - Phi-3-mini-4k-instruct-q4.gguf

    Crea el directorio models si no existe:

```Bash
        mkdir -p models
```

    Coloca el archivo Phi-3-mini-4k-instruct-q4.gguf dentro de la carpeta models.
    La ruta final del modelo deberÃ­a ser pdi_studio_ai/models/Phi-3-mini-4k-instruct-q4.gguf.

## â–¶ï¸ EjecuciÃ³n

Una vez que hayas instalado todas las dependencias y descargado el modelo LLM, puedes ejecutar la aplicaciÃ³n:

```Bash
python main.py
```
## ğŸ“‚ Estructura del Proyecto

pdi_studio_ai/
â”œâ”€â”€ main.py                     # Punto de entrada principal de la aplicaciÃ³n.
â”œâ”€â”€ requirements.txt            # Dependencias de Python.
â”œâ”€â”€ .gitignore                  # Archivos y directorios ignorados por Git.
â”œâ”€â”€ models/                     # Directorio para modelos LLM (ej. Phi-3-mini-4k-instruct-q4.gguf).
â”œâ”€â”€ config/
â”‚   â””â”€â”€ presets.json            # Archivo JSON para guardar y cargar presets de filtros.
â”œâ”€â”€ video_capture/
â”‚   â””â”€â”€ camera_feed.py          # Clase para manejar la captura de video de la cÃ¡mara.
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filters.py              # DefiniciÃ³n de funciones de filtro y sus metadatos.
â”‚   â”œâ”€â”€ image_processor.py      # Aplica la pipeline de filtros a un frame de imagen.
â”‚   â””â”€â”€ image_processing_worker.py # Hilo para procesamiento de imÃ¡genes en segundo plano.
â””â”€â”€ ui/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main_window.py          # La ventana principal de la aplicaciÃ³n PyQt6.
    â””â”€â”€ widgets/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ filter_control.py   # Widget para controlar un filtro individual (parÃ¡metros, habilitar/deshabilitar).
        â”œâ”€â”€ filter_selector.py  # Widget para seleccionar y aÃ±adir nuevos filtros a la pipeline.
        â”œâ”€â”€ histogram_plotter.py # Widget para mostrar el histograma de la imagen procesada.
        â””â”€â”€ pipeline_manager.py  # Widget para gestionar la lista de filtros en la pipeline (reordenar, eliminar).

## ğŸ›£ï¸ Futuras Implementaciones

Este proyecto es una base sÃ³lida, y hay muchas Ã¡reas para expandir y mejorar:

    MÃ¡s Filtros y Efectos:

        - Implementar una gama mÃ¡s amplia de filtros de OpenCV (ej. Transformada de Hough para detecciÃ³n de lÃ­neas/cÃ­rculos, operaciones morfolÃ³gicas, segmentaciÃ³n por color, etc.).

        - AÃ±adir filtros avanzados o combinaciones predefinidas.

        - Soporte para mÃ¡scaras y regiones de interÃ©s (ROI) para aplicar filtros solo a partes de la imagen.

    Mejoras en la Interfaz de Usuario (UI):

        - Arrastrar y Soltar (Drag & Drop): Implementar la funcionalidad de arrastrar y soltar para reordenar filtros en el PipelineManager de manera mÃ¡s intuitiva.

        - Vista Previa en Tiempo Real (Thumbnails): Mostrar una pequeÃ±a miniatura de la imagen despuÃ©s de cada filtro en la pipeline para depuraciÃ³n visual.

        - Interfaz de Ajuste Fino: Una forma mÃ¡s interactiva de ajustar parÃ¡metros, tal vez con feedback visual en tiempo real en un pequeÃ±o Ã¡rea de vista previa.

        - Temas Oscuros/Claros: Opciones para personalizar la apariencia de la interfaz.

    Capacidades del LLM:

        - "Undo" y "Redo" de Peticiones LLM: Permitir al usuario iterar y refinar las sugerencias del LLM.

        - ConfirmaciÃ³n de ParÃ¡metros: Si el LLM sugiere parÃ¡metros inusuales, pedir confirmaciÃ³n al usuario o resaltar los valores atÃ­picos.

        - GeneraciÃ³n de DescripciÃ³n de Pipelines: Permitir al LLM generar una descripciÃ³n en lenguaje natural de una pipeline de filtros existente.

        - Manejo de Errores SemÃ¡nticos: Mejorar la capacidad del LLM para interpretar peticiones complejas o ambiguas y pedir aclaraciones.

    Carga y Guardado de ImÃ¡genes/Videos:

        - Permitir cargar archivos de imagen y video desde el disco para su procesamiento, no solo el feed de la cÃ¡mara.

        - Funcionalidad para guardar videos procesados.

    OptimizaciÃ³n y Rendimiento:

        - Explorar el uso de GPGPU (CUDA/OpenCL) para el procesamiento de imÃ¡genes para un rendimiento aÃºn mayor, especialmente con resoluciones altas.

        - OptimizaciÃ³n de la comunicaciÃ³n entre hilos para reducir la latencia.

    Funcionalidades Adicionales:

        - Anotaciones: Herramientas para dibujar o aÃ±adir texto a la imagen procesada.

        - CalibraciÃ³n de CÃ¡mara: Opciones bÃ¡sicas de calibraciÃ³n (brillo, contraste, saturaciÃ³n, etc.) si la cÃ¡mara lo soporta.

        - Benchmarks: Herramientas para medir el rendimiento de la pipeline y los filtros individuales.

